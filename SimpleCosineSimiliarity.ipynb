{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'faster',\n",
       "  'harry',\n",
       "  'got',\n",
       "  'to',\n",
       "  'the',\n",
       "  'store',\n",
       "  'the',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'faster',\n",
       "  'harry',\n",
       "  'would',\n",
       "  'get',\n",
       "  'home'],\n",
       " ['harry', 'is', 'hairy', 'and', 'faster', 'than', 'jill'],\n",
       " ['jill', 'is', 'not', 'as', 'hairy', 'as', 'harry']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\",\n",
    "        \"Harry is hairy and faster than Jill.\",\n",
    "        \"Jill is not as hairy as Harry.\"]\n",
    "\n",
    "doc_tokens = [re.findall(r'\\w+', d.lower()) for d in docs]\n",
    "doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'as',\n",
       " 'faster',\n",
       " 'get',\n",
       " 'got',\n",
       " 'hairy',\n",
       " 'harry',\n",
       " 'home',\n",
       " 'is',\n",
       " 'jill',\n",
       " 'not',\n",
       " 'store',\n",
       " 'than',\n",
       " 'the',\n",
       " 'to',\n",
       " 'would']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = sorted(set(sum(doc_tokens, [])))\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('and', 0),\n",
       "             ('as', 0),\n",
       "             ('faster', 0),\n",
       "             ('get', 0),\n",
       "             ('got', 0),\n",
       "             ('hairy', 0),\n",
       "             ('harry', 0),\n",
       "             ('home', 0),\n",
       "             ('is', 0),\n",
       "             ('jill', 0),\n",
       "             ('not', 0),\n",
       "             ('store', 0),\n",
       "             ('than', 0),\n",
       "             ('the', 0),\n",
       "             ('to', 0),\n",
       "             ('would', 0)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "vector_template = OrderedDict((token, 0) for token in lexicon)\n",
    "vector_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('and', 0.09375),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.28125),\n",
       "              ('get', 0.1875),\n",
       "              ('got', 0.1875),\n",
       "              ('hairy', 0),\n",
       "              ('harry', 0.0),\n",
       "              ('home', 0.1875),\n",
       "              ('is', 0),\n",
       "              ('jill', 0),\n",
       "              ('not', 0),\n",
       "              ('store', 0.1875),\n",
       "              ('than', 0),\n",
       "              ('the', 0.5625),\n",
       "              ('to', 0.1875),\n",
       "              ('would', 0.1875)]),\n",
       " OrderedDict([('and', 0.09375),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.09375),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.09375),\n",
       "              ('harry', 0.0),\n",
       "              ('home', 0),\n",
       "              ('is', 0.09375),\n",
       "              ('jill', 0.0),\n",
       "              ('not', 0),\n",
       "              ('store', 0),\n",
       "              ('than', 0.1875),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)]),\n",
       " OrderedDict([('and', 0),\n",
       "              ('as', 0.125),\n",
       "              ('faster', 0),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.09375),\n",
       "              ('harry', 0.0),\n",
       "              ('home', 0),\n",
       "              ('is', 0.09375),\n",
       "              ('jill', 0.0),\n",
       "              ('not', 0.1875),\n",
       "              ('store', 0),\n",
       "              ('than', 0),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "doc_tfidf_vectors = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(vector_template)\n",
    "    tokens = re.findall(r'\\w+', doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in docs:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf\n",
    "    doc_tfidf_vectors.append(vec)\n",
    "\n",
    "doc_tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.253546276418555)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod / (mag_1 * mag_2)\n",
    "\n",
    "cosine_sim(doc_tfidf_vectors[2], doc_tfidf_vectors[0]), cosine_sim(doc_tfidf_vectors[2], doc_tfidf_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0\t1\t2\n",
      "0\t1.0\t0.17\t0.0\t\n",
      "1\t0.17\t1.0\t0.25\t\n",
      "2\t0.0\t0.25\t1.0\t\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t0\\t1\\t2\")\n",
    "for r, doc1 in enumerate(doc_tfidf_vectors):\n",
    "    print(r, end='\\t')\n",
    "    for c, doc2 in enumerate(doc_tfidf_vectors):\n",
    "        print(round(cosine_sim(doc1, doc2), 2), end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6324555320336759\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(vector_template)\n",
    "tokens = re.findall(r'\\w+', query)\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for _doc in docs:\n",
    "        if key in _doc.lower():\n",
    "            docs_containing_key += 1\n",
    "    if docs_containing_key == 0:\n",
    "        continue\n",
    "    tf = value / len(tokens)\n",
    "    idf = len(docs) / docs_containing_key\n",
    "    query_vec[key] = tf * idf\n",
    "\n",
    "print(cosine_sim(query_vec, doc_tfidf_vectors[0]))\n",
    "print(cosine_sim(query_vec, doc_tfidf_vectors[1]))\n",
    "print(cosine_sim(query_vec, doc_tfidf_vectors[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
