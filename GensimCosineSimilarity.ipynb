{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility.\n",
    "# It's a bening warning when Scipy was compiled against an older Numpy version. Safe to\n",
    "# ignore.\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human',\n",
       "  'machine',\n",
       "  'interface',\n",
       "  'for',\n",
       "  'lab',\n",
       "  'abc',\n",
       "  'computer',\n",
       "  'applications'],\n",
       " ['a',\n",
       "  'survey',\n",
       "  'of',\n",
       "  'user',\n",
       "  'opinion',\n",
       "  'of',\n",
       "  'computer',\n",
       "  'system',\n",
       "  'response',\n",
       "  'time'],\n",
       " ['the', 'eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'and', 'human', 'system', 'engineering', 'testing', 'of', 'eps'],\n",
       " ['relation',\n",
       "  'of',\n",
       "  'user',\n",
       "  'perceived',\n",
       "  'response',\n",
       "  'time',\n",
       "  'to',\n",
       "  'error',\n",
       "  'measurement'],\n",
       " ['the', 'generation', 'of', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['the', 'intersection', 'graph', 'of', 'paths', 'in', 'trees'],\n",
       " ['graph',\n",
       "  'minors',\n",
       "  'iv',\n",
       "  'widths',\n",
       "  'of',\n",
       "  'trees',\n",
       "  'and',\n",
       "  'well',\n",
       "  'quasi',\n",
       "  'ordering'],\n",
       " ['graph', 'minors', 'a', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "\n",
    "# Lets tokenize, normalize to lowercase and remove stopwords.\n",
    "\n",
    "stopwords = ['for a of and to the in']\n",
    "tokenized_documents = [[word for word in re.findall(r'\\w+', doc.lower()) if word not in stopwords]\n",
    "                       for doc in documents]\n",
    "tokenized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(42 unique tokens: ['management', 'applications', 'system', 'and', 'of']...) \n",
      "\n",
      "{'management': 17, 'applications': 1, 'system': 13, 'and': 19, 'of': 9, 'user': 15, 'engineering': 20, 'testing': 21, 'response': 11, 'well': 40, 'intersection': 34, 'error': 22, 'quasi': 39, 'opinion': 10, 'binary': 27, 'survey': 12, 'trees': 30, 'perceived': 24, 'random': 29, 'iv': 36, 'to': 26, 'machine': 7, 'widths': 41, 'measurement': 23, 'paths': 35, 'for': 3, 'interface': 5, 'ordering': 38, 'in': 33, 'computer': 2, 'relation': 25, 'minors': 37, 'abc': 0, 'eps': 16, 'human': 4, 'lab': 6, 'generation': 28, 'a': 8, 'graph': 32, 'the': 18, 'time': 14, 'unordered': 31}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_documents)\n",
    "print(dictionary, '\\n')\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1),\n",
       "  (8, 1),\n",
       "  (9, 2),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1)],\n",
       " [(5, 1), (13, 1), (15, 1), (16, 1), (17, 1), (18, 1)],\n",
       " [(4, 1), (9, 1), (13, 2), (16, 1), (19, 1), (20, 1), (21, 1)],\n",
       " [(9, 1),\n",
       "  (11, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1)],\n",
       " [(9, 1), (18, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)],\n",
       " [(9, 1), (18, 1), (30, 1), (32, 1), (33, 1), (34, 1), (35, 1)],\n",
       " [(9, 1),\n",
       "  (19, 1),\n",
       "  (30, 1),\n",
       "  (32, 1),\n",
       "  (36, 1),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1)],\n",
       " [(8, 1), (12, 1), (32, 1), (37, 1)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(tc) for tc in tokenized_documents]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(re.findall(r'\\w+', new_doc.lower()))\n",
    "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = index[tfidf[new_vec]]\n",
    "print(sims)\n",
    "\n",
    "# This produces segmentation fault (core dumped). It's probably an\n",
    "# issue with my environment, so check in another computer...\n",
    "# Anyway, I should still add comments and clean up a bit, so TODO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
